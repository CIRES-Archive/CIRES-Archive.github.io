---
layout: post
title:  "Hechuan's Paper accepted by ICDM"
categories: [ Reading-Group, Hechuan ]
image: assets/images/hechuan-icdm-23.png
comments: true
---

üéâ Congratulations Hechuan! üéâ

We are proud to announce that our PhD student Hechuan has had a paper accepted by the International Conference on Data Mining (ICDM) this year! This is an extraordinary achievement and a testament to Hechuan‚Äôs hard work, dedication, and expertise in the field.

The ICDM conference is a prestigious platform that gathers the best minds in data mining, and to have a paper accepted here speaks volumes about the quality and impact of the research conducted.

üìù About the Paper

**Abstract**: Leveraging the rich relational information from networked data for causal effect estimation has been proven beneficial to deconfounding at the population scale. However, the potential risk of individual-level treatment effect estimation on such data has been largely underexplored. Due to the imbalanced nature of networked observational data, the causal effect predictions for some individuals can severely violate the positivity/overlap assumption, rendering unreliable estimations. To create a more trustworthy causal effect estimator, we propose the uncertainty-aware graph deep kernel learning (GraphDKL) framework to model the prediction uncertainty with a Gaussian process and identify unreliable estimations. Also, when learning node representations with graph neural networks for downstream causal estimators, the notorious feature collapse issue can lead to non-distinguishable latent representations of individuals. Such an issue hinders the effectiveness of spotting samples that violate the positivity, as their representations can collide with those of high-confidence samples. To address this issue, we restrain GraphDKL with Lipschitz constant via spectral normalization to decouple the collapsed representations, such that predictions with high and low uncertainties can be effectively distinguished in the latent space. Furthermore, by establishing a sparse variational optimization scheme, GraphDKL is scalable to large graphs. Extensive experiments demonstrate the superiority of our proposed method in uncertainty-aware causal effect estimation on networked data



#ICDM2023 #DataMining #Congratulations
